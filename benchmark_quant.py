"""
í€€íŠ¸/ë”¥ëŸ¬ë‹ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
ìœˆë„ìš° vs ë§¥ë¶ ì„±ëŠ¥ ë¹„êµìš©
"""
import time
import platform
import numpy as np

print("=" * 50)
print(f"ì‹œìŠ¤í…œ: {platform.system()} {platform.machine()}")
print(f"í”„ë¡œì„¸ì„œ: {platform.processor()}")
print("=" * 50)

# 1. NumPy í–‰ë ¬ ì—°ì‚° ë²¤ì¹˜ë§ˆí¬
print("\n[1] NumPy í–‰ë ¬ ì—°ì‚° (5000x5000)")
start = time.time()
a = np.random.randn(5000, 5000)
b = np.random.randn(5000, 5000)
c = np.dot(a, b)
numpy_time = time.time() - start
print(f"ì†Œìš” ì‹œê°„: {numpy_time:.2f}ì´ˆ")

# 2. PyTorch ë”¥ëŸ¬ë‹ ë²¤ì¹˜ë§ˆí¬
try:
    import torch
    import torch.nn as nn
    
    device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\n[2] PyTorch ë”¥ëŸ¬ë‹ (device: {device})")
    
    # ê°„ë‹¨í•œ ì‹ ê²½ë§
    model = nn.Sequential(
        nn.Linear(1000, 2000),
        nn.ReLU(),
        nn.Linear(2000, 2000),
        nn.ReLU(),
        nn.Linear(2000, 1000),
    ).to(device)
    
    x = torch.randn(1000, 1000).to(device)
    
    # ì›Œë°ì—…
    for _ in range(10):
        _ = model(x)
    
    # ë²¤ì¹˜ë§ˆí¬
    start = time.time()
    for _ in range(100):
        _ = model(x)
    if device != "cpu":
        torch.cuda.synchronize() if device == "cuda" else torch.mps.synchronize()
    pytorch_time = time.time() - start
    print(f"100íšŒ ì¶”ë¡  ì†Œìš” ì‹œê°„: {pytorch_time:.2f}ì´ˆ")
    
    # í•™ìŠµ ë²¤ì¹˜ë§ˆí¬
    print("\n[3] PyTorch í•™ìŠµ (LSTM ì‹œê³„ì—´)")
    
    lstm = nn.LSTM(input_size=50, hidden_size=128, num_layers=2, batch_first=True).to(device)
    fc = nn.Linear(128, 1).to(device)
    optimizer = torch.optim.Adam(list(lstm.parameters()) + list(fc.parameters()), lr=0.001)
    criterion = nn.MSELoss()
    
    # ê°€ìƒ ì£¼ê°€ ë°ì´í„° (ë°°ì¹˜ 64, ì‹œí€€ìŠ¤ 100, í”¼ì²˜ 50)
    train_x = torch.randn(64, 100, 50).to(device)
    train_y = torch.randn(64, 1).to(device)
    
    start = time.time()
    for epoch in range(50):
        optimizer.zero_grad()
        out, _ = lstm(train_x)
        pred = fc(out[:, -1, :])
        loss = criterion(pred, train_y)
        loss.backward()
        optimizer.step()
    if device != "cpu":
        torch.cuda.synchronize() if device == "cuda" else torch.mps.synchronize()
    lstm_time = time.time() - start
    print(f"50 ì—í­ í•™ìŠµ ì†Œìš” ì‹œê°„: {lstm_time:.2f}ì´ˆ")

except ImportError:
    print("\n[!] PyTorch ë¯¸ì„¤ì¹˜ - pip install torch")
    pytorch_time = None
    lstm_time = None

# 3. íŒë‹¤ìŠ¤ ë°ì´í„° ì²˜ë¦¬
try:
    import pandas as pd
    
    print("\n[4] Pandas ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬")
    start = time.time()
    df = pd.DataFrame({
        'date': pd.date_range('2000-01-01', periods=1000000, freq='T'),
        'open': np.random.randn(1000000).cumsum() + 100,
        'high': np.random.randn(1000000).cumsum() + 101,
        'low': np.random.randn(1000000).cumsum() + 99,
        'close': np.random.randn(1000000).cumsum() + 100,
        'volume': np.random.randint(1000, 100000, 1000000)
    })
    df['ma20'] = df['close'].rolling(20).mean()
    df['ma60'] = df['close'].rolling(60).mean()
    df['rsi'] = df['close'].pct_change().rolling(14).apply(lambda x: 100 - 100/(1 + (x[x>0].sum() / abs(x[x<0].sum()) if x[x<0].sum() != 0 else 1)))
    df['signal'] = np.where(df['ma20'] > df['ma60'], 1, -1)
    pandas_time = time.time() - start
    print(f"100ë§Œ í–‰ ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {pandas_time:.2f}ì´ˆ")

except ImportError:
    print("\n[!] Pandas ë¯¸ì„¤ì¹˜")
    pandas_time = None

# ê²°ê³¼ ìš”ì•½
print("\n" + "=" * 50)
print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
print("=" * 50)
print(f"NumPy í–‰ë ¬ê³± (5000x5000): {numpy_time:.2f}ì´ˆ")
if pytorch_time:
    print(f"PyTorch ì¶”ë¡  (100íšŒ): {pytorch_time:.2f}ì´ˆ")
if lstm_time:
    print(f"LSTM í•™ìŠµ (50ì—í­): {lstm_time:.2f}ì´ˆ")
if pandas_time:
    print(f"Pandas ì²˜ë¦¬ (100ë§Œí–‰): {pandas_time:.2f}ì´ˆ")
print("=" * 50)
